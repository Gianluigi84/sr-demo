<launch>
	<!--
<node pkg="planning_environment" type="clear_known_objects" name="kinect_clear_objects"
output="screen">
<remap
		from="robot_description" to="hand_description"/>

<remap from="cloud_in"
		to="/camera/depth/points" />
<remap from="cloud_out" to="/camera/depth/known"
		/>
<param name="sensor_frame" type="string" value="openni_camera" />

<param
		name="fixed_frame" type="string" value="base_link" />
<param name="object_padd"
		type="double" value="0.02" />
<param name="object_scale" type="double" value="1.0"
		/>
</node>
-->
	<node pkg="robot_self_filter" type="self_filter" name="kinect_self_filter"
		respawn="true"
		output="screen">

		<remap from="robot_description" to="hand_description"/>
		
		<!-- The topic for the input cloud -->
		<remap from="cloud_in" to="/camera/depth/points2" />

		<!-- The topic for the output cloud -->
		<remap from="cloud_out" to="/camera/depth/points_filtered" />

		<!-- The frame of the sensor used to obtain the data to be filtered; This
			parameter is optional. If it is not specified, shadow points will be 
			considered outside
			-->
		<!--<param name="sensor_frame" type="string" value="openni_camera" />-->

		<!-- Minimum distance to sensor (for point not to be considered inside) -->
		<param name="min_sensor_dist" type="double" value="0.05" />

		<!-- The padding to be added for the body parts the robot can see -->
		<param name="self_see_padd" type="double" value="0.01" />

		<!-- The scaling to be added for the body parts the robot can see -->
		<param name="self_see_scale" type="double" value="1.0" />

		<!-- The names of the links the sensor can see -->
		<rosparam command="load" file="$(find sr_object_manipulation_launch)/config/self_filter.yaml"
			/>

	</node>
</launch>

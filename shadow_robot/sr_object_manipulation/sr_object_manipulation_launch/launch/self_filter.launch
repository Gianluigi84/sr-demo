<launch>  

   <include file="$(find 3dnav_pr2)/launch/pr2_planning_environment.launch" />

   <node pkg="robot_self_filter" type="self_filter" respawn="true" output="screen">

     <!-- The topic for the input cloud -->
     <remap from="cloud_in" to="/camera/depth/points2" />

     <!-- The topic for the output cloud -->
     <remap from="cloud_out" to="/camera/points_filtered" />

     <!-- The frame of the sensor used to obtain the data to be
       filtered; This parameter is optional. If it is not specified,
       shadow points will be considered outside -->
     <param name="sensor_frame" type="string" value="kinect_depth" />

     <!-- Minimum distance to sensor (for point not to be considered inside) -->
     <param name="min_sensor_dist" type="double" value="0.01" />

     <!-- The padding to be added for the body parts the robot can see -->
     <param name="self_see_padd" type="double" value="0.02" />

     <!-- The scaling to be added for the body parts the robot can see -->
     <param name="self_see_scale" type="double" value="1.0" />
     
     <!-- The names of the links the sensor can see -->
     <param name="self_see_links" type="string" value="" />
     
   </node>
</launch>
